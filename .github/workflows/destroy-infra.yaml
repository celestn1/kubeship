# .github/workflows/destroy-infra.yaml

name: Destroy KubeShip Infrastructure on AWS EKS

on:
  workflow_dispatch:   # manual trigger

concurrency:
  group: destroy-infra-${{ github.ref }}
  cancel-in-progress: true

permissions:
  id-token: write     # for OIDC
  contents: read

env:
  AWS_REGION:                    ${{ secrets.AWS_REGION }}
  TF_STATE_BUCKET:               ${{ secrets.TF_STATE_BUCKET }}
  TF_LOCK_TABLE:                 ${{ secrets.TF_LOCK_TABLE }}
  TF_VAR_project_name:           ${{ secrets.TF_PROJECT_NAME }}
  TF_VAR_environment:            ${{ secrets.TF_ENVIRONMENT }}
  TF_VAR_eks_cluster_name:       ${{ secrets.TF_EKS_CLUSTER_NAME }}
  TF_VAR_gitops_repo_url:        ${{ secrets.TF_GITOPS_REPO_URL }}
  TF_VAR_target_revision:        ${{ secrets.TF_TARGET_REVISION }}
  TF_VAR_argocd_app_manifest_path: ${{ secrets.TF_ARGOCD_APP_MANIFEST_PATH }}
  TF_VAR_terraform_caller_arn:   ${{ secrets.CI_IAM_ROLE_ARN }}

jobs:
  destroy:
    name: Terraform Destroy
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: terraform

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Authenticate to AWS via OIDC
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume:    ${{ secrets.CI_IAM_ROLE_ARN }}
          aws-region:        ${{ env.AWS_REGION }}
          role-session-name: github-actions-eks-destroy

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.6

      - name: Terraform Init
        run: |
          terraform init -upgrade \
            -backend-config="bucket=${TF_STATE_BUCKET}" \
            -backend-config="key=infra/terraform.tfstate" \
            -backend-config="region=${REGION}" \
            -backend-config="dynamodb_table=${TF_LOCK_TABLE}"

      - name: Get Kubernetes config
        run: |
          EKS_CLUSTER_NAME="${{ env.TF_VAR_eks_cluster_name }}"
          if aws eks describe-cluster \
              --name "${EKS_CLUSTER_NAME}" \
              --region "${AWS_REGION}" \
              > /dev/null 2>&1; then
            echo "Cluster ${EKS_CLUSTER_NAME} exists, updating kubeconfig"
            aws eks update-kubeconfig \
              --name "${EKS_CLUSTER_NAME}" \
              --region "${AWS_REGION}"
          else
            echo "Cluster ${EKS_CLUSTER_NAME} not found, skipping kubeconfig"
          fi

      - name: Remove Helm releases explicitly
        run: |
          helm uninstall argocd -n argocd || true
          helm uninstall external-secrets -n external-secrets || true
          helm uninstall cert-manager -n cert-manager || true
        continue-on-error: true

      - name: Delete ArgoCD apps
        run: |
          kubectl delete -f ../manifests/argocd-applications -n argocd --ignore-not-found=true
        continue-on-error: true

      - name: Delete non-ArgoCD manifests (skip missing CRDs)
        run: |
          # Tear down our Ingresses first so the ALB & WAF can be deleted
          kubectl delete ingress kubeship-ingress  -n nginx-gateway  --ignore-not-found || true
          kubectl delete ingress argocd-ingress     -n argocd          --ignore-not-found || true

          # Then remove any base manifests (e.g. cluster-issuer / certificate) if their CRDs exist
          for file in ../manifests/base/*.yaml; do
            if kubectl apply --dry-run=client --server-side -f "$file" &> /dev/null; then
              kubectl delete -f "$file" --ignore-not-found || true
            else
              echo "Skipping $file: CRD not present"
            fi
          done
        continue-on-error: true

      - name: Force-delete AWS Secrets Manager entries
        run: |
          secrets=$(aws secretsmanager list-secrets --include-planned-deletion --query "SecretList[?starts_with(Name,'/kubeship/')].Name" --output text)
          for secret in $secrets; do
            echo "Deleting secret: $secret"
            aws secretsmanager delete-secret --secret-id "$secret" --force-delete-without-recovery || true
          done
        continue-on-error: true          

      - name: Terraform Destroy
        run: terraform destroy -auto-approve