# ------------------------------
# .github/workflows/deploy-infra.yaml
# ------------------------------
name: Deploy KubeShip Infrastructure on AWS EKS

on:
  push:
    branches: [ main ]
    paths:
      - 'terraform/**'
      - 'helm-charts/**'
      - 'manifests/**'
      - 'microservices/**'
      - 'nginx/**'
      - 'shared/**'      
      - '.github/workflows/deploy-infra.yaml'

permissions: 
  id-token: write    # to assume AWS role via OIDC
  contents: read

env:
  # Docker/ECR
  IMAGE_TAG:       latest
  ECR_REPO_1:      auth-service
  ECR_REPO_2:      frontend
  ECR_REPO_3:      nginx-gateway

  # AWS & Terraform
  AWS_REGION:                      ${{ secrets.AWS_REGION }}
  AWS_ACCOUNT_ID:                  ${{ secrets.AWS_ACCOUNT_ID }}
  TF_STATE_BUCKET:                 ${{ secrets.TF_STATE_BUCKET }}
  TF_LOCK_TABLE:                   ${{ secrets.TF_LOCK_TABLE }}
  TF_VAR_project_name:             ${{ secrets.TF_PROJECT_NAME }}
  TF_VAR_environment:              ${{ secrets.TF_ENVIRONMENT }}
  TF_VAR_eks_cluster_name:         ${{ secrets.TF_EKS_CLUSTER_NAME }}
  TF_VAR_gitops_repo_url:          ${{ secrets.TF_GITOPS_REPO_URL }}
  TF_VAR_target_revision:          ${{ secrets.TF_TARGET_REVISION }}
  TF_VAR_argocd_app_manifest_path: ${{ secrets.TF_ARGOCD_APP_MANIFEST_PATH }}
  TF_VAR_availability_zones:       '["${{ secrets.TF_AVAILABILITY_ZONE_1 }}","${{ secrets.TF_AVAILABILITY_ZONE_2 }}"]'
  TF_VAR_terraform_caller_arn:     ${{ secrets.CI_IAM_ROLE_ARN }}

jobs:
  build-and-push:
    name: Build & Push Docker Images
    runs-on: ubuntu-latest
    outputs:
      auth-digest:     ${{ steps.auth-digest.outputs.digest }}
      frontend-digest: ${{ steps.frontend-digest.outputs.digest }}
      nginx-digest:    ${{ steps.nginx-digest.outputs.digest }}

    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS creds for ECR
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-region:            ${{ env.AWS_REGION }}
          aws-access-key-id:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: Ensure ECR repos
        run: |
          for svc in auth-service frontend nginx-gateway; do
            aws ecr describe-repositories --repository-names "${TF_VAR_project_name}-$svc" --region "${AWS_REGION}" \
              || aws ecr create-repository --repository-name "${TF_VAR_project_name}-$svc" --region "${AWS_REGION}"
          done

      - uses: aws-actions/amazon-ecr-login@v2
      - uses: docker/setup-qemu-action@v2
      - uses: docker/setup-buildx-action@v2
        with:
          driver: docker-container
          use: true

      - name: Detect changed services
        id: changes
        uses: dorny/paths-filter@v2
        with:
          filters: |
            auth-service:
              - 'microservices/auth-service/**'
            frontend:
              - 'microservices/frontend/**'
            nginx-gateway:
              - 'nginx/**'
            shared:
              - 'shared/**'


      - name: Build & Push auth-service
        id: auth-digest
        if: ${{ steps.changes.outputs['auth-service'] == 'true' || steps.changes.outputs.shared == 'true' }}        
        run: |
          docker build -t auth-service:${{ env.IMAGE_TAG }} -f ./microservices/auth-service/Dockerfile ./microservices/auth-service        
          URI=${{ env.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/${{ env.TF_VAR_project_name }}-${{ env.ECR_REPO_1 }}
          docker tag auth-service:${{ env.IMAGE_TAG }} $URI:${{ env.IMAGE_TAG }}
          docker push $URI:${{ env.IMAGE_TAG }}
          echo "auth-digest=$(docker inspect --format='{{index .RepoDigests 0}}' $URI:${{ env.IMAGE_TAG }})" >> $GITHUB_OUTPUT

      - name: Build & Push frontend
        if: ${{ steps.changes.outputs.frontend == 'true' || steps.changes.outputs.shared == 'true' }}      
        run: |
          docker build --build-arg VITE_API_URL=/v1/auth -t frontend:${{ env.IMAGE_TAG }} -f microservices/frontend/Dockerfile .
          URI=${{ env.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/${{ env.TF_VAR_project_name }}-${{ env.ECR_REPO_2 }}
          docker tag frontend:${{ env.IMAGE_TAG }} $URI:${{ env.IMAGE_TAG }}
          docker push $URI:${{ env.IMAGE_TAG }}
          echo "frontend-digest=$(docker inspect --format='{{index .RepoDigests 0}}' $URI:${{ env.IMAGE_TAG }})" >> $GITHUB_OUTPUT

      - name: Build & Push nginx-gateway
        if: ${{ steps.changes.outputs['nginx-gateway'] == 'true' || steps.changes.outputs.shared == 'true' }}      
        run: |
          docker build -t nginx-gateway:${{ env.IMAGE_TAG }} -f ./nginx/Dockerfile ./nginx
          URI=${{ env.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/${{ env.TF_VAR_project_name }}-${{ env.ECR_REPO_3 }}
          docker tag nginx-gateway:${{ env.IMAGE_TAG }} $URI:${{ env.IMAGE_TAG }}
          docker push $URI:${{ env.IMAGE_TAG }}
          echo "nginx-digest=$(docker inspect --format='{{index .RepoDigests 0}}' $URI:${{ env.IMAGE_TAG }})" >> $GITHUB_OUTPUT

  deploy:
    name: Deploy Infrastructure & Apps
    needs: build-and-push
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: terraform

    steps:
      - uses: actions/checkout@v3

      - name: Authenticate to AWS via OIDC
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume:    ${{ env.TF_VAR_terraform_caller_arn }}
          aws-region:        ${{ env.AWS_REGION }}
          role-session-name: github-actions-eks

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.6

      - name: Terraform Init
        run: |
          terraform init -upgrade \
            -backend-config="bucket=${TF_STATE_BUCKET}" \
            -backend-config="key=infra/terraform.tfstate" \
            -backend-config="region=${AWS_REGION}" \
            -backend-config="dynamodb_table=${TF_LOCK_TABLE}"

      # 1. VPC
      - name: Terraform Plan (VPC only)
        run: terraform plan -target=module.vpc -out=tfplan-vpc

      - name: Terraform Apply (VPC only)
        run: terraform apply -auto-approve tfplan-vpc

      # 2. EKS
      - name: Terraform Plan (EKS only)
        id: plan
        run: |
          terraform plan -target=module.eks -out=tfplan-cluster \
            -var="auth_image_digest=${{ needs.build-and-push.outputs.auth-digest }}" \
            -var="frontend_image_digest=${{ needs.build-and-push.outputs.frontend-digest }}" \
            -var="nginx_image_digest=${{ needs.build-and-push.outputs.nginx-digest }}"
        continue-on-error: true

      - name: Terraform plan status
        if: steps.plan.outcome == 'failure'
        run: exit 1

      - name: Terraform Apply (EKS only)
        id: apply
        run: terraform apply -auto-approve -input=false -parallelism=1 tfplan-cluster

      # 4. Wait for AWS Load Balancer Controller webhook to be ready
      - name: Get Kubernetes config
        id: getconfig
        if: steps.apply.outcome == 'success'
        run: aws eks update-kubeconfig --name ${{ env.TF_VAR_eks_cluster_name }} --region ${{ env.AWS_REGION }}


      # 3. ALB Controller
      - name: Terraform Plan (ALB Controller only)
        run: terraform plan -target=module.alb_controller -out=tfplan-alb
      - name: Terraform Apply (ALB Controller only)
        run: terraform apply -auto-approve tfplan-alb
                
      - name: Wait for AWS Load Balancer Controller deployment
        run: |
          kubectl -n kube-system rollout status deployment/aws-load-balancer-controller --timeout=180s

      # 5. Apply the rest of the infra (all modules)
      - name: Terraform Plan & Apply (full sync)
        env:
          
          TF_VAR_secrets_map: |
            {
              "/kubeship/auth": {
                "DATABASE_URL":    "${{ secrets.DATABASE_URL }}",
                "JWT_SECRET_KEY":  "${{ secrets.JWT_SECRET_KEY }}",
                "JWT_ALGORITHM":   "${{ secrets.JWT_ALGORITHM }}",
                "REDIS_URL":       "${{ secrets.REDIS_URL }}"
              },
              "/kubeship/postgres": {
                "POSTGRES_USER":     "${{ secrets.POSTGRES_USER }}",
                "POSTGRES_PASSWORD": "${{ secrets.POSTGRES_PASSWORD }}",
                "POSTGRES_DB":       "${{ secrets.POSTGRES_DB }}"
              }
            }
        run: |
          terraform plan -out=tfplan-full \
            -var="auth_image_digest=${{ needs.build-and-push.outputs.auth-digest }}" \
            -var="frontend_image_digest=${{ needs.build-and-push.outputs.frontend-digest }}" \
            -var="nginx_image_digest=${{ needs.build-and-push.outputs.nginx-digest }}"
          terraform apply -auto-approve tfplan-full


      # 6. Wait for ArgoCD server to be ready
      - name: Wait for ArgoCD server to be ready
        run: |
          kubectl wait --for=condition=available deployment/argocd-server \
            -n argocd --timeout=300s

      # 7. Install ArgoCD Applications
      - name: Apply ArgoCD apps
        run: kubectl apply -f ../manifests/argocd-applications -n argocd

      - name: Wait for nginx-gateway app to sync
        run: kubectl -n argocd wait --for=condition=Synced app/nginx-gateway --timeout=300s

      # 8. Install ArgoCD base manifests
      - name: Apply base manifests
        run: kubectl apply -f ../manifests/base/

      # 9. Check ClusterSecretStore CRD exists
      - name: Check ClusterSecretStore CRD exists
        run: kubectl get crd clustersecretstores.external-secrets.io

      # 10. Force sync ArgoCD apps
      - name: Force sync ArgoCD apps
        run: |
          for app in $(kubectl get applications.argoproj.io -n argocd -o jsonpath='{.items[*].metadata.name}'); do
            kubectl patch application $app -n argocd \
              --type merge -p '{"spec": {"syncPolicy": {"automated": {"prune": true, "selfHeal": true}}}}'
          done

      # 11. Refresh ArgoCD Apps
      - name: Refresh ArgoCD Apps
        run: |
          LB=$(kubectl get svc argocd-server -n argocd \
                 -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          curl -k "http://$LB/api/v1/applications?refresh=true" || true

      # 12. Final: Verify deployed ArgoCD apps
      - name: Verify deployed ArgoCD apps
        run: kubectl get applications -n argocd